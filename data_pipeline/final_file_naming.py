import os
import pandas as pd


# Builds final filenames using manually updated dates and saves to a new CSV.
def build_final_filenames(input_csv="data/manually_updated_committee_names.csv",
                          output_csv="data/final_updated_committee_names.csv"):

    # Load the manually updated CSV
    df = pd.read_csv(input_csv)

    # Ensure required columns exist
    required_columns = ["Committee", "Document Type", "Original File Name",
                        "Extracted Date", "Proposed File Name"]
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"Required column '{col}' not found in {input_csv}")

    # Function to update filename with new date
    def update_filename(row):
        # For Related Documents, use original filename
        if row["Document Type"].lower() == "related documents":
            return row["Original File Name"]
            
        date = row["Extracted Date"]
        # If date was 'unknown' but now has a valid date format
        if ("unknown" in str(row["Proposed File Name"]).lower() and
                date != "unknown" and pd.notna(date)):
            # Extract file extension
            file_ext = os.path.splitext(row["Original File Name"])[1]
            # Build new filename with updated date
            return f"{row['Committee']}_{row['Document Type']}_{date}{file_ext}"
        # If date is still unknown, append part of original filename to make it unique
        elif "unknown" in str(row["Proposed File Name"]).lower():
            # Extract original filename without extension
            orig_name = os.path.splitext(os.path.basename(row["Original File Name"]))[0]
            file_ext = os.path.splitext(row["Original File Name"])[1]
            # Build new filename with unknown date and original filename to ensure uniqueness
            return f"{row['Committee']}_{row['Document Type']}_unknown_{orig_name}{file_ext}"
        return row["Proposed File Name"]

    # Apply the update function to create final filenames
    df["Final File Name"] = df.apply(update_filename, axis=1)

    # Save the updated DataFrame to CSV
    df.to_csv(output_csv, index=False)
    print(f"Final filenames saved to {output_csv}")
    print(f"Rows processed: {len(df)}")

    return df

def verify_folder_file_structure(processed_dir="data/Processed_Committees",
                            final_csv="data/final_updated_committee_names.csv"):
    """
    Verifies that the folder structure in final_updated_committee_names.csv matches
    the actual structure in Processed_Committees.
    Returns True if all matches, False if any mismatches are found, and prints details.
    """

    # Load the final updated CSV
    df = pd.read_csv(final_csv)

    # Ensure required columns exist
    required_columns = ["Committee", "Document Type", "Original File Name"]
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"Required column '{col}' not found in {final_csv}")

    all_match = True
    mismatch_count = 0

    # Check each row in the CSV
    for index, row in df.iterrows():
        # Construct the expected path based on CSV data
        expected_rel_path = os.path.join(
            row["Committee"],
            row["Document Type"],
            row["Original File Name"]
        )
        expected_full_path = os.path.join(processed_dir, expected_rel_path)

        # Check if the committee directory exists
        committee_path = os.path.join(processed_dir, row["Committee"])
        if not os.path.isdir(committee_path):
            print(f"Error at row {index}: Committee directory not found: {committee_path}")
            all_match = False
            mismatch_count += 1
            continue

        # Check if the document type subdirectory exists
        doc_type_path = os.path.join(committee_path, row["Document Type"])
        if not os.path.isdir(doc_type_path):
            print(f"Error at row {index}: Document Type directory not found: {doc_type_path}")
            all_match = False
            mismatch_count += 1
            continue

        # Check if the original file exists
        if not os.path.isfile(expected_full_path):
            print(f"Error at row {index}: File not found at expected path: {expected_full_path}")
            all_match = False
            mismatch_count += 1

    # Summary report
    if all_match:
        print(f"Verification complete: All {len(df)} entries match the folder structure in {processed_dir}")
    else:
        print(f"Verification complete: Found {mismatch_count} mismatches out of {len(df)} entries")

    return all_match


## Renames files in Processed_Committees by replacing just the filename with 'Final File Name', generated by GPT entirely.
def rename_processed_files(
    processed_dir="data/Processed_Committees",
    final_csv="data/final_updated_committee_names.csv"
):
    """
    Renames files in Processed_Committees by replacing just the filename with 'Final File Name'
    EXCEPT for those in 'Related Documents' folder, which are left as-is.
    """

    # Load the final updated CSV
    df = pd.read_csv(final_csv, dtype=str).fillna("")

    # Validate required columns
    required_columns = ["Committee", "Document Type", "Original File Name", "Final File Name"]
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"Required column '{col}' not found in {final_csv}")

    renamed_count = 0
    missing_count = 0

    # If you'd like collision handling, set this to True. Otherwise, files with
    # the same new_path will be overwritten.  I ran into problems with collisions at one point, and added this check for debugging purposes.
    HANDLE_COLLISIONS = True

    for _, row in df.iterrows():
        committee = row["Committee"].strip()
        doc_type = row["Document Type"].strip()
        old_filename = row["Original File Name"].strip()
        new_filename = row["Final File Name"].strip()

        old_path = os.path.join(processed_dir, committee, doc_type, old_filename)
        new_path = os.path.join(processed_dir, committee, doc_type, new_filename)

        # Skip renaming if Document Type = "Related Documents"
        if doc_type.lower() == "related documents":
            print(f"Skipping rename (Related Documents): {old_path}")
            continue

        # Check if the old file exists
        if not os.path.exists(old_path):
            print(f"Warning: File not found for renaming: {old_path}")
            missing_count += 1
            continue

        # Handle collisions if desired
        if HANDLE_COLLISIONS and os.path.exists(new_path):
            base, ext = os.path.splitext(new_path)
            i = 1
            alt_path = f"{base}_{i}{ext}"
            while os.path.exists(alt_path):
                i += 1
                alt_path = f"{base}_{i}{ext}"
            new_path = alt_path
            print(f"Collision: {old_path} -> {new_path}")

        # Rename the file (change only the filename, same folder)
        os.rename(old_path, new_path)
        renamed_count += 1
        print(f"Renamed: {old_path} -> {new_path}")

    # Summary
    total_rows = len(df)
    print("\nSummary:")
    print(f"  Total rows in CSV:  {total_rows}")
    print(f"  Renamed files:      {renamed_count}")
    print(f"  Missing files:      {missing_count}")

    return renamed_count